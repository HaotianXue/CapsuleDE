{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alienware\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alienware\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alienware\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Alienware\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []  # 16659\n",
    "test_data = []  # 810"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "\n",
      "\n",
      "\" 5 . Science includes such diverse fields as astronomy , biology , computer sciences , geology , logic , physics , chemistry , and mathematics ( [ link ] ) .\"\t\"0\"\n",
      "\n",
      "\" 2 . It becomes clear from this definition that the application of the scientific method plays a major role in science .\"\t\"0\"\n",
      "\n",
      "\n",
      "\n",
      "Files get!...\n"
     ]
    }
   ],
   "source": [
    "'''读取文件'''\n",
    "print('Reading files...')\n",
    "print('\\n')\n",
    "train_f = open(\"train.txt\", encoding='utf-8')\n",
    "for line in train_f:\n",
    "    train_data.append(line)\n",
    "train_f.close()\n",
    "\n",
    "test_f = open(\"test.txt\", encoding='utf-8')\n",
    "for line in test_f:\n",
    "    test_data.append(line)\n",
    "test_f.close()\n",
    "print(train_data[0])\n",
    "print(test_data[0])\n",
    "print('\\n')\n",
    "print('Files get!...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting...\n",
      "\n",
      "\n",
      "['Science includes such diverse fields as astronomy , biology , computer sciences , geology , logic , physics , chemistry , and mathematics ( [ link ] )', '0']\n",
      "['It becomes clear from this definition that the application of the scientific method plays a major role in science', '0']\n",
      "\n",
      "\n",
      "All data sets are formatted!\n"
     ]
    }
   ],
   "source": [
    "'''去掉开头序号-> [[句子(单词间以,为分割)], 0/1]'''\n",
    "print('Formatting...')\n",
    "print('\\n')\n",
    "train_set = []\n",
    "for unit in train_data:\n",
    "    temp = unit.split(' ')\n",
    "    if temp[1].isdigit():\n",
    "        # 判断第一个字符是否为数字，如果是则去掉，如果不是则取句子\n",
    "        temp = temp[3:-1]\n",
    "        # 当前temp中的最后一部分为\"\\t.\\n\",\"最后一个引号\" 为了保证格式规范，先去掉，最后在取corpus的时候加上句号即可\n",
    "        # training_set.append(([temp, unit[-3:-2]]))\n",
    "        train_set.append([' '.join(temp), unit[-3:-2]])\n",
    "        # unit[-3:-2]为当前句子的label\n",
    "    else:\n",
    "        # temp[1]为引号，应去掉\n",
    "        temp = temp[1:-1]\n",
    "        # training_set.append(([temp, unit[-3:-2]]))\n",
    "        train_set.append([' '.join(temp), unit[-3:-2]])\n",
    "\n",
    "test_set = []\n",
    "for unit in test_data:\n",
    "    temp = unit.split(' ')\n",
    "    if temp[1].isdigit():\n",
    "        temp = temp[3:-1]\n",
    "        # training_set.append(([temp, unit[-3:-2]]))\n",
    "        test_set.append([' '.join(temp), unit[-3:-2]])\n",
    "    else:\n",
    "        temp = temp[1:-1]\n",
    "        # training_set.append(([temp, unit[-3:-2]]))\n",
    "        test_set.append([' '.join(temp), unit[-3:-2]])\n",
    "\n",
    "print(train_set[0])\n",
    "print(test_set[0])\n",
    "print('\\n')\n",
    "print('All data sets are formatted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizeing...\n",
      "\n",
      "\n",
      "[['Science', 'includes', 'such', 'diverse', 'fields', 'as', 'astronomy', ',', 'biology', ',', 'computer', 'sciences', ',', 'geology', ',', 'logic', ',', 'physics', ',', 'chemistry', ',', 'and', 'mathematics', '(', '[', 'link', ']', ')'], '0']\n",
      "[['It', 'becomes', 'clear', 'from', 'this', 'definition', 'that', 'the', 'application', 'of', 'the', 'scientific', 'method', 'plays', 'a', 'major', 'role', 'in', 'science'], '0']\n",
      "\n",
      "\n",
      "Tokenization completed!\n"
     ]
    }
   ],
   "source": [
    "print('Tokenizeing...')\n",
    "print('\\n')\n",
    "\n",
    "def tokenize(data):\n",
    "    res = []\n",
    "    for samples in data:\n",
    "        # nltk.word_tokenize用于取tokens\n",
    "        temp_t = nltk.word_tokenize(samples[0])\n",
    "        res.append([temp_t, samples[1]])\n",
    "    return res\n",
    "\n",
    "\n",
    "train_set = tokenize(train_set)\n",
    "test_set = tokenize(test_set)\n",
    "print(train_set[0])\n",
    "print(test_set[0])\n",
    "print('\\n')\n",
    "print('Tokenization completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing stopwords...\n",
      "\n",
      "\n",
      "[['Science', 'includes', 'diverse', 'fields', 'astronomy', ',', 'biology', ',', 'computer', 'sciences', ',', 'geology', ',', 'logic', ',', 'physics', ',', 'chemistry', ',', 'mathematics', '(', '[', 'link', ']', ')'], '0']\n",
      "[['It', 'becomes', 'clear', 'definition', 'application', 'scientific', 'method', 'plays', 'major', 'role', 'science'], '0']\n",
      "\n",
      "\n",
      "Stopwords removed!\n"
     ]
    }
   ],
   "source": [
    "print('Removing stopwords...')\n",
    "print('\\n')\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# stop_words为英文所有stop words的集合\n",
    "\n",
    "\n",
    "def Remove_stopwords(data):\n",
    "    res = []\n",
    "    temp = []\n",
    "    for sets in data:\n",
    "        for w in sets[0]:\n",
    "            # 如果对于句子中任意一个单词不属于stop_words则将其加入新的dataset\n",
    "            if w not in stop_words:\n",
    "                temp.append(w)\n",
    "        res.append([temp, sets[1]])\n",
    "        temp = []\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "train_set = Remove_stopwords(train_set)\n",
    "test_set = Remove_stopwords(test_set)\n",
    "print(train_set[0])\n",
    "print(test_set[0])\n",
    "print('\\n')\n",
    "print('Stopwords removed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming...\n",
      "\n",
      "\n",
      "[['scienc', 'includ', 'divers', 'field', 'astronomi', ',', 'biolog', ',', 'comput', 'scienc', ',', 'geolog', ',', 'logic', ',', 'physic', ',', 'chemistri', ',', 'mathemat', '(', '[', 'link', ']', ')'], '0']\n",
      "[['It', 'becom', 'clear', 'definit', 'applic', 'scientif', 'method', 'play', 'major', 'role', 'scienc'], '0']\n",
      "\n",
      "\n",
      "Stemming completed!\n"
     ]
    }
   ],
   "source": [
    "print('Stemming...')\n",
    "print('\\n')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "def Stemming(data):\n",
    "    res = []\n",
    "    stemmed_words_temp = []\n",
    "    for units in data:\n",
    "        for w in units[0]:\n",
    "            #ps.stem(w):对当前单词w取stem word\n",
    "            stemmed_words_temp.append(ps.stem(w))\n",
    "\n",
    "        res.append([stemmed_words_temp, units[1]])\n",
    "        stemmed_words_temp = []\n",
    "    return res\n",
    "\n",
    "\n",
    "train_set = Stemming(train_set)\n",
    "test_set = Stemming(test_set)\n",
    "print(train_set[0])\n",
    "print(test_set[0])\n",
    "print('\\n')\n",
    "print('Stemming completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization...\n",
      "\n",
      "\n",
      "[['scienc', 'includ', 'divers', 'field', 'astronomi', ',', 'biolog', ',', 'comput', 'scienc', ',', 'geolog', ',', 'logic', ',', 'physic', ',', 'chemistri', ',', 'mathemat', '(', '[', 'link', ']', ')'], '0']\n",
      "[['It', 'becom', 'clear', 'definit', 'applic', 'scientif', 'method', 'play', 'major', 'role', 'scienc'], '0']\n",
      "\n",
      "\n",
      "Lemmatization completed!\n"
     ]
    }
   ],
   "source": [
    "print('Lemmatization...')\n",
    "print('\\n')\n",
    "lem = WordNetLemmatizer()\n",
    "stem = PorterStemmer()\n",
    "\n",
    "\n",
    "def Lemmatization(data):\n",
    "    lem_words_temp = []\n",
    "    res = []\n",
    "    for atoms in data:\n",
    "        for w in atoms[0]:\n",
    "            #lem.lemmatize(w, \"v\"): 对当前单词w取Lemmatization\n",
    "            lem_words_temp.append(lem.lemmatize(w, \"v\"))\n",
    "        res.append([lem_words_temp, atoms[1]])\n",
    "        lem_words_temp = []\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "train_set = Lemmatization(train_set)\n",
    "test_set = Lemmatization(test_set)\n",
    "print(train_set[0])\n",
    "print(test_set[0])\n",
    "print('\\n')\n",
    "print('Lemmatization completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus and labels gathering...\n",
      "\n",
      "\n",
      "len of corpus_sum: 17469\n",
      "['scienc includ divers field astronomi , biolog , comput scienc , geolog , logic , physic , chemistri , mathemat ( [ link ] ).', 'howev , field scienc relat physic world phenomena process consid natur scienc.', 'thu , museum natur scienc might contain item list.', 'In deduct reason , pattern think move opposit direct compar induct reason.', 'deduct reason form logic think use gener principl law forecast specif result.']\n",
      "['0' '1' '0' '0' '1']\n",
      "['0' '1' '0' '1' '1']\n",
      "(16659,)\n",
      "(810,)\n",
      "\n",
      "\n",
      "Corpus and labels get!\n"
     ]
    }
   ],
   "source": [
    "print('Corpus and labels gathering...')\n",
    "print('\\n')\n",
    "corpus_test = []\n",
    "corpus_train = []\n",
    "\n",
    "\n",
    "def Gathering_corpus(data):\n",
    "    res = []\n",
    "    temp_res = []\n",
    "    for aas in data:\n",
    "        #corpus中仅仅需要第一个unit，即句子\n",
    "        temp_res.append(aas[0])\n",
    "\n",
    "    for aaas in temp_res:\n",
    "        # 对于scikit-learn中的vectorizer，corpus必须为一句一句话的集合，而并非tokens。所以这里必须join然后加上句号。\n",
    "        temp_ff = ' '.join(aaas)\n",
    "        temp_ff = temp_ff + '.'\n",
    "        res.append(temp_ff)\n",
    "    return res\n",
    "\n",
    "\n",
    "corpus_train = Gathering_corpus(train_set)\n",
    "corpus_test = Gathering_corpus(test_set)\n",
    "# train和test的corpus之和，成为corpus_sum\n",
    "corpus_sum = []\n",
    "corpus_sum = corpus_train\n",
    "for things in corpus_test:\n",
    "    corpus_sum.append(things)\n",
    "print('len of corpus_sum:', len(corpus_sum))\n",
    "print(corpus_sum[:5])\n",
    "#取出label: Y_train and Y_test\n",
    "Y_train = []\n",
    "for thing in train_set:\n",
    "    Y_train.append(thing[1])\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = []\n",
    "for that in test_set:\n",
    "    Y_test.append(that[1])\n",
    "Y_test = np.array(Y_test)\n",
    "print(Y_train[:5])\n",
    "print(Y_test[:5])\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print('\\n')\n",
    "print('Corpus and labels get!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf processing...\n",
      "\n",
      "\n",
      "(16659, 14675)\n",
      "(810, 14675)\n",
      "(17469, 14675)\n",
      "\n",
      "\n",
      "tfidf get!\n"
     ]
    }
   ],
   "source": [
    "print('tfidf processing...')\n",
    "print('\\n')\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_tfidf = vectorizer_tfidf.fit_transform(corpus_sum)\n",
    "X_train_tfidf = X_tfidf[:16659]\n",
    "X_test_tfidf = X_tfidf[16659:17469]\n",
    "X_train_tfidf = X_train_tfidf.toarray()\n",
    "X_test_tfidf = X_test_tfidf.toarray()\n",
    "X_tfidf_arr = X_tfidf.toarray()\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_test_tfidf.shape)\n",
    "print(X_tfidf_arr.shape)\n",
    "print('\\n')\n",
    "print('tfidf get!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Format_into_array(data):\n",
    "    res = []\n",
    "    for items in data:\n",
    "        temp = int(items)\n",
    "        res.append(temp)\n",
    "    res = np.array(res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 1 0 0 1 0]\n",
      "[0 1 0 0 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "Y_test = Format_into_array(Y_test)\n",
    "Y_train = Format_into_array(Y_train)\n",
    "print(Y_test[:10])\n",
    "print(Y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain=xgb.DMatrix(X_train_tfidf,label=Y_train)\n",
    "dtest=xgb.DMatrix(X_test_tfidf, label=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'booster':'gbtree',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'max_depth':30,\n",
    "        'lambda':15,\n",
    "        'subsample':0.75,\n",
    "        'colsample_bytree':0.75,\n",
    "        'min_child_weight':1.75,\n",
    "        'eta': 0.025,\n",
    "        'seed':0,\n",
    "        'silent':1,\n",
    "        'gamma':0.15,\n",
    "        'learning_rate' : 0.02}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtrain,'train'), (dtest,'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.6691\ttest-auc:0.664249\n",
      "[1]\ttrain-auc:0.711755\ttest-auc:0.69491\n",
      "[2]\ttrain-auc:0.732849\ttest-auc:0.720166\n",
      "[3]\ttrain-auc:0.737611\ttest-auc:0.722608\n",
      "[4]\ttrain-auc:0.749213\ttest-auc:0.730803\n",
      "[5]\ttrain-auc:0.755788\ttest-auc:0.734316\n",
      "[6]\ttrain-auc:0.759711\ttest-auc:0.735575\n",
      "[7]\ttrain-auc:0.761815\ttest-auc:0.739927\n",
      "[8]\ttrain-auc:0.76284\ttest-auc:0.741902\n",
      "[9]\ttrain-auc:0.763928\ttest-auc:0.74671\n",
      "[10]\ttrain-auc:0.763744\ttest-auc:0.74492\n",
      "[11]\ttrain-auc:0.765004\ttest-auc:0.743481\n",
      "[12]\ttrain-auc:0.767304\ttest-auc:0.746513\n",
      "[13]\ttrain-auc:0.768289\ttest-auc:0.74535\n",
      "[14]\ttrain-auc:0.7679\ttest-auc:0.745183\n",
      "[15]\ttrain-auc:0.768074\ttest-auc:0.743638\n",
      "[16]\ttrain-auc:0.767778\ttest-auc:0.744135\n",
      "[17]\ttrain-auc:0.768472\ttest-auc:0.744371\n",
      "[18]\ttrain-auc:0.768792\ttest-auc:0.742406\n",
      "[19]\ttrain-auc:0.77018\ttest-auc:0.743453\n",
      "[20]\ttrain-auc:0.770447\ttest-auc:0.743102\n",
      "[21]\ttrain-auc:0.772356\ttest-auc:0.747423\n",
      "[22]\ttrain-auc:0.77218\ttest-auc:0.747662\n",
      "[23]\ttrain-auc:0.772539\ttest-auc:0.748416\n",
      "[24]\ttrain-auc:0.773125\ttest-auc:0.74933\n",
      "[25]\ttrain-auc:0.773426\ttest-auc:0.750107\n",
      "[26]\ttrain-auc:0.774033\ttest-auc:0.750643\n",
      "[27]\ttrain-auc:0.774458\ttest-auc:0.750466\n",
      "[28]\ttrain-auc:0.77433\ttest-auc:0.75361\n",
      "[29]\ttrain-auc:0.775196\ttest-auc:0.754586\n",
      "[30]\ttrain-auc:0.776269\ttest-auc:0.75668\n",
      "[31]\ttrain-auc:0.777636\ttest-auc:0.756693\n",
      "[32]\ttrain-auc:0.77782\ttest-auc:0.755165\n",
      "[33]\ttrain-auc:0.778232\ttest-auc:0.755244\n",
      "[34]\ttrain-auc:0.779366\ttest-auc:0.755916\n",
      "[35]\ttrain-auc:0.780011\ttest-auc:0.756519\n",
      "[36]\ttrain-auc:0.780647\ttest-auc:0.756649\n",
      "[37]\ttrain-auc:0.780715\ttest-auc:0.758105\n",
      "[38]\ttrain-auc:0.782584\ttest-auc:0.760837\n",
      "[39]\ttrain-auc:0.783029\ttest-auc:0.762242\n",
      "[40]\ttrain-auc:0.783666\ttest-auc:0.761976\n",
      "[41]\ttrain-auc:0.784545\ttest-auc:0.762628\n",
      "[42]\ttrain-auc:0.785461\ttest-auc:0.764705\n",
      "[43]\ttrain-auc:0.785853\ttest-auc:0.766284\n",
      "[44]\ttrain-auc:0.786264\ttest-auc:0.765104\n",
      "[45]\ttrain-auc:0.786692\ttest-auc:0.765656\n",
      "[46]\ttrain-auc:0.786925\ttest-auc:0.766229\n",
      "[47]\ttrain-auc:0.787264\ttest-auc:0.766489\n",
      "[48]\ttrain-auc:0.787446\ttest-auc:0.766748\n",
      "[49]\ttrain-auc:0.787941\ttest-auc:0.766639\n",
      "[50]\ttrain-auc:0.788455\ttest-auc:0.76553\n",
      "[51]\ttrain-auc:0.788703\ttest-auc:0.764384\n",
      "[52]\ttrain-auc:0.789\ttest-auc:0.764852\n",
      "[53]\ttrain-auc:0.789594\ttest-auc:0.765755\n",
      "[54]\ttrain-auc:0.790051\ttest-auc:0.765653\n",
      "[55]\ttrain-auc:0.790487\ttest-auc:0.764869\n",
      "[56]\ttrain-auc:0.791256\ttest-auc:0.764456\n",
      "[57]\ttrain-auc:0.791817\ttest-auc:0.765428\n",
      "[58]\ttrain-auc:0.792257\ttest-auc:0.766086\n",
      "[59]\ttrain-auc:0.792695\ttest-auc:0.767082\n",
      "[60]\ttrain-auc:0.793186\ttest-auc:0.765882\n",
      "[61]\ttrain-auc:0.793644\ttest-auc:0.766823\n",
      "[62]\ttrain-auc:0.794351\ttest-auc:0.767055\n",
      "[63]\ttrain-auc:0.794847\ttest-auc:0.767638\n",
      "[64]\ttrain-auc:0.795555\ttest-auc:0.767982\n",
      "[65]\ttrain-auc:0.79603\ttest-auc:0.767403\n",
      "[66]\ttrain-auc:0.796242\ttest-auc:0.767232\n",
      "[67]\ttrain-auc:0.796639\ttest-auc:0.766625\n",
      "[68]\ttrain-auc:0.797121\ttest-auc:0.766291\n",
      "[69]\ttrain-auc:0.79753\ttest-auc:0.766403\n",
      "[70]\ttrain-auc:0.797732\ttest-auc:0.766315\n",
      "[71]\ttrain-auc:0.798252\ttest-auc:0.766427\n",
      "[72]\ttrain-auc:0.799442\ttest-auc:0.766721\n",
      "[73]\ttrain-auc:0.799779\ttest-auc:0.767832\n",
      "[74]\ttrain-auc:0.800172\ttest-auc:0.768003\n",
      "[75]\ttrain-auc:0.800675\ttest-auc:0.76816\n",
      "[76]\ttrain-auc:0.801069\ttest-auc:0.768289\n",
      "[77]\ttrain-auc:0.801659\ttest-auc:0.767907\n",
      "[78]\ttrain-auc:0.801898\ttest-auc:0.767638\n",
      "[79]\ttrain-auc:0.802278\ttest-auc:0.767137\n",
      "[80]\ttrain-auc:0.802741\ttest-auc:0.767089\n",
      "[81]\ttrain-auc:0.80317\ttest-auc:0.767348\n",
      "[82]\ttrain-auc:0.804041\ttest-auc:0.767618\n",
      "[83]\ttrain-auc:0.804815\ttest-auc:0.76804\n",
      "[84]\ttrain-auc:0.805141\ttest-auc:0.7686\n",
      "[85]\ttrain-auc:0.805612\ttest-auc:0.76846\n",
      "[86]\ttrain-auc:0.806065\ttest-auc:0.769115\n",
      "[87]\ttrain-auc:0.806356\ttest-auc:0.769139\n",
      "[88]\ttrain-auc:0.806903\ttest-auc:0.769452\n",
      "[89]\ttrain-auc:0.807561\ttest-auc:0.769412\n",
      "[90]\ttrain-auc:0.808496\ttest-auc:0.769664\n",
      "[91]\ttrain-auc:0.809099\ttest-auc:0.770121\n",
      "[92]\ttrain-auc:0.809656\ttest-auc:0.770366\n",
      "[93]\ttrain-auc:0.809875\ttest-auc:0.770281\n",
      "[94]\ttrain-auc:0.810081\ttest-auc:0.770257\n",
      "[95]\ttrain-auc:0.810333\ttest-auc:0.771028\n",
      "[96]\ttrain-auc:0.81115\ttest-auc:0.7717\n",
      "[97]\ttrain-auc:0.811377\ttest-auc:0.771714\n",
      "[98]\ttrain-auc:0.811811\ttest-auc:0.772198\n",
      "[99]\ttrain-auc:0.81205\ttest-auc:0.77256\n",
      "[100]\ttrain-auc:0.812628\ttest-auc:0.772907\n",
      "[101]\ttrain-auc:0.813405\ttest-auc:0.773248\n",
      "[102]\ttrain-auc:0.813729\ttest-auc:0.77346\n",
      "[103]\ttrain-auc:0.81417\ttest-auc:0.773767\n",
      "[104]\ttrain-auc:0.814421\ttest-auc:0.773603\n",
      "[105]\ttrain-auc:0.814595\ttest-auc:0.773815\n",
      "[106]\ttrain-auc:0.814844\ttest-auc:0.773364\n",
      "[107]\ttrain-auc:0.815481\ttest-auc:0.773972\n",
      "[108]\ttrain-auc:0.815731\ttest-auc:0.774681\n",
      "[109]\ttrain-auc:0.816043\ttest-auc:0.774749\n",
      "[110]\ttrain-auc:0.816281\ttest-auc:0.774012\n",
      "[111]\ttrain-auc:0.816395\ttest-auc:0.774122\n",
      "[112]\ttrain-auc:0.816781\ttest-auc:0.774831\n",
      "[113]\ttrain-auc:0.817305\ttest-auc:0.775124\n",
      "[114]\ttrain-auc:0.81773\ttest-auc:0.775302\n",
      "[115]\ttrain-auc:0.818083\ttest-auc:0.775609\n",
      "[116]\ttrain-auc:0.818334\ttest-auc:0.776175\n",
      "[117]\ttrain-auc:0.818799\ttest-auc:0.776127\n",
      "[118]\ttrain-auc:0.819098\ttest-auc:0.77627\n",
      "[119]\ttrain-auc:0.819189\ttest-auc:0.776393\n",
      "[120]\ttrain-auc:0.819646\ttest-auc:0.776727\n",
      "[121]\ttrain-auc:0.82013\ttest-auc:0.776441\n",
      "[122]\ttrain-auc:0.820468\ttest-auc:0.776564\n",
      "[123]\ttrain-auc:0.820646\ttest-auc:0.776618\n",
      "[124]\ttrain-auc:0.821053\ttest-auc:0.776618\n",
      "[125]\ttrain-auc:0.821458\ttest-auc:0.777027\n",
      "[126]\ttrain-auc:0.821888\ttest-auc:0.777075\n",
      "[127]\ttrain-auc:0.822121\ttest-auc:0.777102\n",
      "[128]\ttrain-auc:0.822208\ttest-auc:0.777102\n",
      "[129]\ttrain-auc:0.822524\ttest-auc:0.776959\n",
      "[130]\ttrain-auc:0.822827\ttest-auc:0.7773\n",
      "[131]\ttrain-auc:0.823121\ttest-auc:0.77773\n",
      "[132]\ttrain-auc:0.823239\ttest-auc:0.77788\n",
      "[133]\ttrain-auc:0.823513\ttest-auc:0.778225\n",
      "[134]\ttrain-auc:0.823768\ttest-auc:0.778361\n",
      "[135]\ttrain-auc:0.823898\ttest-auc:0.778061\n",
      "[136]\ttrain-auc:0.824156\ttest-auc:0.778388\n",
      "[137]\ttrain-auc:0.824427\ttest-auc:0.778729\n",
      "[138]\ttrain-auc:0.824765\ttest-auc:0.779023\n",
      "[139]\ttrain-auc:0.825083\ttest-auc:0.778852\n",
      "[140]\ttrain-auc:0.825416\ttest-auc:0.778777\n",
      "[141]\ttrain-auc:0.825751\ttest-auc:0.778235\n",
      "[142]\ttrain-auc:0.825955\ttest-auc:0.77874\n",
      "[143]\ttrain-auc:0.826177\ttest-auc:0.778474\n",
      "[144]\ttrain-auc:0.826346\ttest-auc:0.778705\n",
      "[145]\ttrain-auc:0.826651\ttest-auc:0.778665\n",
      "[146]\ttrain-auc:0.826955\ttest-auc:0.778903\n",
      "[147]\ttrain-auc:0.827189\ttest-auc:0.779169\n",
      "[148]\ttrain-auc:0.827381\ttest-auc:0.779183\n",
      "[149]\ttrain-auc:0.827687\ttest-auc:0.779173\n",
      "[150]\ttrain-auc:0.827909\ttest-auc:0.779159\n",
      "[151]\ttrain-auc:0.828116\ttest-auc:0.779258\n",
      "[152]\ttrain-auc:0.828482\ttest-auc:0.779159\n",
      "[153]\ttrain-auc:0.828695\ttest-auc:0.779388\n",
      "[154]\ttrain-auc:0.828947\ttest-auc:0.779319\n",
      "[155]\ttrain-auc:0.82914\ttest-auc:0.779517\n",
      "[156]\ttrain-auc:0.829386\ttest-auc:0.779722\n",
      "[157]\ttrain-auc:0.829504\ttest-auc:0.780104\n",
      "[158]\ttrain-auc:0.829742\ttest-auc:0.779926\n",
      "[159]\ttrain-auc:0.829988\ttest-auc:0.780213\n",
      "[160]\ttrain-auc:0.830127\ttest-auc:0.780261\n",
      "[161]\ttrain-auc:0.830342\ttest-auc:0.780281\n",
      "[162]\ttrain-auc:0.830566\ttest-auc:0.780418\n",
      "[163]\ttrain-auc:0.830786\ttest-auc:0.78025\n",
      "[164]\ttrain-auc:0.83102\ttest-auc:0.779732\n",
      "[165]\ttrain-auc:0.831178\ttest-auc:0.780005\n",
      "[166]\ttrain-auc:0.831294\ttest-auc:0.780019\n",
      "[167]\ttrain-auc:0.83151\ttest-auc:0.779957\n",
      "[168]\ttrain-auc:0.831868\ttest-auc:0.7798\n",
      "[169]\ttrain-auc:0.83196\ttest-auc:0.780175\n",
      "[170]\ttrain-auc:0.832253\ttest-auc:0.780353\n",
      "[171]\ttrain-auc:0.832472\ttest-auc:0.780401\n",
      "[172]\ttrain-auc:0.832779\ttest-auc:0.780257\n",
      "[173]\ttrain-auc:0.833052\ttest-auc:0.780175\n",
      "[174]\ttrain-auc:0.833259\ttest-auc:0.780305\n",
      "[175]\ttrain-auc:0.833515\ttest-auc:0.780489\n",
      "[176]\ttrain-auc:0.833797\ttest-auc:0.780701\n",
      "[177]\ttrain-auc:0.833971\ttest-auc:0.780523\n",
      "[178]\ttrain-auc:0.834192\ttest-auc:0.780373\n",
      "[179]\ttrain-auc:0.834354\ttest-auc:0.780537\n",
      "[180]\ttrain-auc:0.83458\ttest-auc:0.780366\n",
      "[181]\ttrain-auc:0.83477\ttest-auc:0.780571\n",
      "[182]\ttrain-auc:0.835001\ttest-auc:0.780823\n",
      "[183]\ttrain-auc:0.83528\ttest-auc:0.780728\n",
      "[184]\ttrain-auc:0.835574\ttest-auc:0.780878\n",
      "[185]\ttrain-auc:0.835716\ttest-auc:0.78126\n",
      "[186]\ttrain-auc:0.836001\ttest-auc:0.781444\n",
      "[187]\ttrain-auc:0.836175\ttest-auc:0.781533\n",
      "[188]\ttrain-auc:0.836407\ttest-auc:0.781833\n",
      "[189]\ttrain-auc:0.836603\ttest-auc:0.782058\n",
      "[190]\ttrain-auc:0.836809\ttest-auc:0.782208\n",
      "[191]\ttrain-auc:0.837053\ttest-auc:0.782624\n",
      "[192]\ttrain-auc:0.837279\ttest-auc:0.782781\n",
      "[193]\ttrain-auc:0.83743\ttest-auc:0.783102\n",
      "[194]\ttrain-auc:0.837654\ttest-auc:0.783013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195]\ttrain-auc:0.837797\ttest-auc:0.7833\n",
      "[196]\ttrain-auc:0.838005\ttest-auc:0.783368\n",
      "[197]\ttrain-auc:0.838212\ttest-auc:0.783388\n",
      "[198]\ttrain-auc:0.838429\ttest-auc:0.783402\n",
      "[199]\ttrain-auc:0.838555\ttest-auc:0.783276\n",
      "[200]\ttrain-auc:0.838761\ttest-auc:0.783317\n",
      "[201]\ttrain-auc:0.83891\ttest-auc:0.783774\n",
      "[202]\ttrain-auc:0.839141\ttest-auc:0.783736\n",
      "[203]\ttrain-auc:0.839306\ttest-auc:0.783716\n",
      "[204]\ttrain-auc:0.839487\ttest-auc:0.783886\n",
      "[205]\ttrain-auc:0.839647\ttest-auc:0.783995\n",
      "[206]\ttrain-auc:0.839792\ttest-auc:0.78433\n",
      "[207]\ttrain-auc:0.839999\ttest-auc:0.784534\n",
      "[208]\ttrain-auc:0.840125\ttest-auc:0.784548\n",
      "[209]\ttrain-auc:0.840409\ttest-auc:0.784684\n",
      "[210]\ttrain-auc:0.840518\ttest-auc:0.784868\n",
      "[211]\ttrain-auc:0.840635\ttest-auc:0.78495\n",
      "[212]\ttrain-auc:0.840784\ttest-auc:0.784916\n",
      "[213]\ttrain-auc:0.841102\ttest-auc:0.784957\n",
      "[214]\ttrain-auc:0.841323\ttest-auc:0.784759\n",
      "[215]\ttrain-auc:0.841499\ttest-auc:0.784964\n",
      "[216]\ttrain-auc:0.841678\ttest-auc:0.785046\n",
      "[217]\ttrain-auc:0.841825\ttest-auc:0.784991\n",
      "[218]\ttrain-auc:0.842002\ttest-auc:0.784971\n",
      "[219]\ttrain-auc:0.842143\ttest-auc:0.7851\n",
      "[220]\ttrain-auc:0.842412\ttest-auc:0.785714\n",
      "[221]\ttrain-auc:0.842625\ttest-auc:0.786059\n",
      "[222]\ttrain-auc:0.84278\ttest-auc:0.786113\n",
      "[223]\ttrain-auc:0.842956\ttest-auc:0.786141\n",
      "[224]\ttrain-auc:0.843169\ttest-auc:0.786113\n",
      "[225]\ttrain-auc:0.843348\ttest-auc:0.785943\n",
      "[226]\ttrain-auc:0.843504\ttest-auc:0.786222\n",
      "[227]\ttrain-auc:0.843693\ttest-auc:0.786284\n",
      "[228]\ttrain-auc:0.843892\ttest-auc:0.786686\n",
      "[229]\ttrain-auc:0.844065\ttest-auc:0.786727\n",
      "[230]\ttrain-auc:0.844254\ttest-auc:0.786768\n",
      "[231]\ttrain-auc:0.844445\ttest-auc:0.786536\n",
      "[232]\ttrain-auc:0.84466\ttest-auc:0.786468\n",
      "[233]\ttrain-auc:0.844895\ttest-auc:0.786584\n",
      "[234]\ttrain-auc:0.845074\ttest-auc:0.786407\n",
      "[235]\ttrain-auc:0.845197\ttest-auc:0.786147\n",
      "[236]\ttrain-auc:0.845404\ttest-auc:0.786168\n",
      "[237]\ttrain-auc:0.845613\ttest-auc:0.786147\n",
      "[238]\ttrain-auc:0.845765\ttest-auc:0.78612\n",
      "[239]\ttrain-auc:0.845923\ttest-auc:0.786188\n",
      "[240]\ttrain-auc:0.846184\ttest-auc:0.78625\n",
      "[241]\ttrain-auc:0.846319\ttest-auc:0.786175\n",
      "[242]\ttrain-auc:0.846516\ttest-auc:0.786168\n",
      "[243]\ttrain-auc:0.84665\ttest-auc:0.786359\n",
      "[244]\ttrain-auc:0.846777\ttest-auc:0.786277\n",
      "[245]\ttrain-auc:0.846984\ttest-auc:0.786761\n",
      "[246]\ttrain-auc:0.847146\ttest-auc:0.787\n",
      "[247]\ttrain-auc:0.847296\ttest-auc:0.787416\n",
      "[248]\ttrain-auc:0.847499\ttest-auc:0.7876\n",
      "[249]\ttrain-auc:0.847687\ttest-auc:0.787894\n",
      "[250]\ttrain-auc:0.847863\ttest-auc:0.787976\n",
      "[251]\ttrain-auc:0.848021\ttest-auc:0.787805\n",
      "[252]\ttrain-auc:0.848156\ttest-auc:0.787873\n",
      "[253]\ttrain-auc:0.84834\ttest-auc:0.787846\n",
      "[254]\ttrain-auc:0.84848\ttest-auc:0.787812\n",
      "[255]\ttrain-auc:0.848673\ttest-auc:0.788289\n",
      "[256]\ttrain-auc:0.848808\ttest-auc:0.788303\n",
      "[257]\ttrain-auc:0.848981\ttest-auc:0.788415\n",
      "[258]\ttrain-auc:0.849131\ttest-auc:0.78862\n",
      "[259]\ttrain-auc:0.849282\ttest-auc:0.788504\n",
      "[260]\ttrain-auc:0.849482\ttest-auc:0.788613\n",
      "[261]\ttrain-auc:0.849661\ttest-auc:0.78877\n",
      "[262]\ttrain-auc:0.849882\ttest-auc:0.788832\n",
      "[263]\ttrain-auc:0.85003\ttest-auc:0.789145\n",
      "[264]\ttrain-auc:0.85017\ttest-auc:0.789132\n",
      "[265]\ttrain-auc:0.85028\ttest-auc:0.789466\n",
      "[266]\ttrain-auc:0.850455\ttest-auc:0.789452\n",
      "[267]\ttrain-auc:0.8506\ttest-auc:0.789507\n",
      "[268]\ttrain-auc:0.850752\ttest-auc:0.789684\n",
      "[269]\ttrain-auc:0.850858\ttest-auc:0.789746\n",
      "[270]\ttrain-auc:0.851027\ttest-auc:0.789534\n",
      "[271]\ttrain-auc:0.851165\ttest-auc:0.789698\n",
      "[272]\ttrain-auc:0.851249\ttest-auc:0.789548\n",
      "[273]\ttrain-auc:0.851467\ttest-auc:0.789377\n",
      "[274]\ttrain-auc:0.851581\ttest-auc:0.789418\n",
      "[275]\ttrain-auc:0.851724\ttest-auc:0.789357\n",
      "[276]\ttrain-auc:0.851849\ttest-auc:0.789405\n",
      "[277]\ttrain-auc:0.851977\ttest-auc:0.7895\n",
      "[278]\ttrain-auc:0.852081\ttest-auc:0.789602\n",
      "[279]\ttrain-auc:0.852208\ttest-auc:0.78978\n",
      "[280]\ttrain-auc:0.852393\ttest-auc:0.78995\n",
      "[281]\ttrain-auc:0.852554\ttest-auc:0.790046\n",
      "[282]\ttrain-auc:0.852745\ttest-auc:0.78995\n",
      "[283]\ttrain-auc:0.852944\ttest-auc:0.789766\n",
      "[284]\ttrain-auc:0.853136\ttest-auc:0.789827\n",
      "[285]\ttrain-auc:0.853293\ttest-auc:0.789868\n",
      "[286]\ttrain-auc:0.853382\ttest-auc:0.789937\n",
      "[287]\ttrain-auc:0.853545\ttest-auc:0.790237\n",
      "[288]\ttrain-auc:0.853724\ttest-auc:0.790421\n",
      "[289]\ttrain-auc:0.853878\ttest-auc:0.790762\n",
      "[290]\ttrain-auc:0.854007\ttest-auc:0.790817\n",
      "[291]\ttrain-auc:0.854138\ttest-auc:0.790782\n",
      "[292]\ttrain-auc:0.854318\ttest-auc:0.79083\n",
      "[293]\ttrain-auc:0.854464\ttest-auc:0.790892\n",
      "[294]\ttrain-auc:0.854639\ttest-auc:0.791062\n",
      "[295]\ttrain-auc:0.854759\ttest-auc:0.791001\n",
      "[296]\ttrain-auc:0.854908\ttest-auc:0.790707\n",
      "[297]\ttrain-auc:0.855023\ttest-auc:0.790632\n",
      "[298]\ttrain-auc:0.855161\ttest-auc:0.790482\n",
      "[299]\ttrain-auc:0.855334\ttest-auc:0.790441\n",
      "[300]\ttrain-auc:0.855486\ttest-auc:0.790571\n",
      "[301]\ttrain-auc:0.855637\ttest-auc:0.790803\n",
      "[302]\ttrain-auc:0.855803\ttest-auc:0.790789\n",
      "[303]\ttrain-auc:0.855951\ttest-auc:0.790742\n",
      "[304]\ttrain-auc:0.856085\ttest-auc:0.790462\n",
      "[305]\ttrain-auc:0.856231\ttest-auc:0.790619\n",
      "[306]\ttrain-auc:0.856347\ttest-auc:0.790864\n",
      "[307]\ttrain-auc:0.85652\ttest-auc:0.79096\n",
      "[308]\ttrain-auc:0.856632\ttest-auc:0.790973\n",
      "[309]\ttrain-auc:0.856742\ttest-auc:0.791062\n",
      "[310]\ttrain-auc:0.856903\ttest-auc:0.791001\n",
      "[311]\ttrain-auc:0.857041\ttest-auc:0.791355\n",
      "[312]\ttrain-auc:0.857225\ttest-auc:0.791492\n",
      "[313]\ttrain-auc:0.857368\ttest-auc:0.79154\n",
      "[314]\ttrain-auc:0.85749\ttest-auc:0.791451\n",
      "[315]\ttrain-auc:0.857659\ttest-auc:0.791396\n",
      "[316]\ttrain-auc:0.857761\ttest-auc:0.791594\n",
      "[317]\ttrain-auc:0.857869\ttest-auc:0.791765\n",
      "[318]\ttrain-auc:0.857967\ttest-auc:0.791847\n",
      "[319]\ttrain-auc:0.858065\ttest-auc:0.792154\n",
      "[320]\ttrain-auc:0.858214\ttest-auc:0.792372\n",
      "[321]\ttrain-auc:0.858292\ttest-auc:0.792733\n",
      "[322]\ttrain-auc:0.858431\ttest-auc:0.792733\n",
      "[323]\ttrain-auc:0.858561\ttest-auc:0.792829\n",
      "[324]\ttrain-auc:0.858714\ttest-auc:0.792924\n",
      "[325]\ttrain-auc:0.858855\ttest-auc:0.792972\n",
      "[326]\ttrain-auc:0.858982\ttest-auc:0.79274\n",
      "[327]\ttrain-auc:0.859105\ttest-auc:0.792767\n",
      "[328]\ttrain-auc:0.859245\ttest-auc:0.792692\n",
      "[329]\ttrain-auc:0.85937\ttest-auc:0.792754\n",
      "[330]\ttrain-auc:0.859547\ttest-auc:0.792856\n",
      "[331]\ttrain-auc:0.85971\ttest-auc:0.793129\n",
      "[332]\ttrain-auc:0.859839\ttest-auc:0.793197\n",
      "[333]\ttrain-auc:0.859961\ttest-auc:0.793054\n",
      "[334]\ttrain-auc:0.86008\ttest-auc:0.793143\n",
      "[335]\ttrain-auc:0.860177\ttest-auc:0.793238\n",
      "[336]\ttrain-auc:0.860306\ttest-auc:0.793204\n",
      "[337]\ttrain-auc:0.860394\ttest-auc:0.793306\n",
      "[338]\ttrain-auc:0.860523\ttest-auc:0.793286\n",
      "[339]\ttrain-auc:0.860666\ttest-auc:0.793259\n",
      "[340]\ttrain-auc:0.860832\ttest-auc:0.793306\n",
      "[341]\ttrain-auc:0.860946\ttest-auc:0.793156\n",
      "[342]\ttrain-auc:0.861058\ttest-auc:0.793525\n",
      "[343]\ttrain-auc:0.861147\ttest-auc:0.793354\n",
      "[344]\ttrain-auc:0.861254\ttest-auc:0.793286\n",
      "[345]\ttrain-auc:0.861424\ttest-auc:0.793265\n",
      "[346]\ttrain-auc:0.861517\ttest-auc:0.793381\n",
      "[347]\ttrain-auc:0.861682\ttest-auc:0.793566\n",
      "[348]\ttrain-auc:0.86182\ttest-auc:0.79347\n",
      "[349]\ttrain-auc:0.861958\ttest-auc:0.793651\n",
      "[350]\ttrain-auc:0.862076\ttest-auc:0.793583\n",
      "[351]\ttrain-auc:0.862233\ttest-auc:0.793777\n",
      "[352]\ttrain-auc:0.862398\ttest-auc:0.793913\n",
      "[353]\ttrain-auc:0.862545\ttest-auc:0.793818\n",
      "[354]\ttrain-auc:0.862662\ttest-auc:0.793927\n",
      "[355]\ttrain-auc:0.862857\ttest-auc:0.794138\n",
      "[356]\ttrain-auc:0.862942\ttest-auc:0.794118\n",
      "[357]\ttrain-auc:0.863077\ttest-auc:0.793961\n",
      "[358]\ttrain-auc:0.863182\ttest-auc:0.793975\n",
      "[359]\ttrain-auc:0.863272\ttest-auc:0.794063\n",
      "[360]\ttrain-auc:0.863382\ttest-auc:0.793995\n",
      "[361]\ttrain-auc:0.863481\ttest-auc:0.794023\n",
      "[362]\ttrain-auc:0.86363\ttest-auc:0.793961\n",
      "[363]\ttrain-auc:0.863718\ttest-auc:0.794043\n",
      "[364]\ttrain-auc:0.863834\ttest-auc:0.794159\n",
      "[365]\ttrain-auc:0.863978\ttest-auc:0.794098\n",
      "[366]\ttrain-auc:0.864093\ttest-auc:0.794138\n",
      "[367]\ttrain-auc:0.864229\ttest-auc:0.794091\n",
      "[368]\ttrain-auc:0.864355\ttest-auc:0.79435\n",
      "[369]\ttrain-auc:0.864449\ttest-auc:0.794551\n",
      "[370]\ttrain-auc:0.864587\ttest-auc:0.794517\n",
      "[371]\ttrain-auc:0.864712\ttest-auc:0.794677\n",
      "[372]\ttrain-auc:0.864837\ttest-auc:0.79493\n",
      "[373]\ttrain-auc:0.864954\ttest-auc:0.795012\n",
      "[374]\ttrain-auc:0.865127\ttest-auc:0.794793\n",
      "[375]\ttrain-auc:0.865219\ttest-auc:0.794841\n",
      "[376]\ttrain-auc:0.865296\ttest-auc:0.794691\n",
      "[377]\ttrain-auc:0.865333\ttest-auc:0.794732\n",
      "[378]\ttrain-auc:0.865433\ttest-auc:0.794725\n",
      "[379]\ttrain-auc:0.865605\ttest-auc:0.794807\n",
      "[380]\ttrain-auc:0.865736\ttest-auc:0.794773\n",
      "[381]\ttrain-auc:0.8659\ttest-auc:0.794882\n",
      "[382]\ttrain-auc:0.866042\ttest-auc:0.7948\n",
      "[383]\ttrain-auc:0.86616\ttest-auc:0.794903\n",
      "[384]\ttrain-auc:0.866264\ttest-auc:0.794875\n",
      "[385]\ttrain-auc:0.866402\ttest-auc:0.794937\n",
      "[386]\ttrain-auc:0.866502\ttest-auc:0.794746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[387]\ttrain-auc:0.866602\ttest-auc:0.794677\n",
      "[388]\ttrain-auc:0.866753\ttest-auc:0.794616\n",
      "[389]\ttrain-auc:0.866881\ttest-auc:0.794841\n",
      "[390]\ttrain-auc:0.867012\ttest-auc:0.794923\n",
      "[391]\ttrain-auc:0.867105\ttest-auc:0.795053\n",
      "[392]\ttrain-auc:0.867278\ttest-auc:0.794991\n",
      "[393]\ttrain-auc:0.867356\ttest-auc:0.795025\n",
      "[394]\ttrain-auc:0.867454\ttest-auc:0.79495\n",
      "[395]\ttrain-auc:0.867564\ttest-auc:0.795087\n",
      "[396]\ttrain-auc:0.867684\ttest-auc:0.795046\n",
      "[397]\ttrain-auc:0.867792\ttest-auc:0.794998\n",
      "[398]\ttrain-auc:0.867895\ttest-auc:0.795039\n",
      "[399]\ttrain-auc:0.868018\ttest-auc:0.795203\n",
      "[400]\ttrain-auc:0.868141\ttest-auc:0.795244\n",
      "[401]\ttrain-auc:0.868206\ttest-auc:0.795319\n",
      "[402]\ttrain-auc:0.868332\ttest-auc:0.79525\n",
      "[403]\ttrain-auc:0.868428\ttest-auc:0.795175\n",
      "[404]\ttrain-auc:0.868498\ttest-auc:0.795169\n",
      "[405]\ttrain-auc:0.868614\ttest-auc:0.795148\n",
      "[406]\ttrain-auc:0.868729\ttest-auc:0.795148\n",
      "[407]\ttrain-auc:0.868891\ttest-auc:0.795128\n",
      "[408]\ttrain-auc:0.868999\ttest-auc:0.794991\n",
      "[409]\ttrain-auc:0.869111\ttest-auc:0.794943\n",
      "[410]\ttrain-auc:0.869257\ttest-auc:0.794964\n",
      "[411]\ttrain-auc:0.869401\ttest-auc:0.79508\n",
      "[412]\ttrain-auc:0.869469\ttest-auc:0.794998\n",
      "[413]\ttrain-auc:0.869624\ttest-auc:0.794957\n",
      "[414]\ttrain-auc:0.869752\ttest-auc:0.794937\n",
      "[415]\ttrain-auc:0.869938\ttest-auc:0.795053\n",
      "[416]\ttrain-auc:0.870047\ttest-auc:0.795107\n",
      "[417]\ttrain-auc:0.870146\ttest-auc:0.795121\n",
      "[418]\ttrain-auc:0.87027\ttest-auc:0.795134\n",
      "[419]\ttrain-auc:0.870377\ttest-auc:0.795312\n",
      "[420]\ttrain-auc:0.870442\ttest-auc:0.795278\n",
      "[421]\ttrain-auc:0.870544\ttest-auc:0.795523\n",
      "[422]\ttrain-auc:0.870645\ttest-auc:0.795748\n",
      "[423]\ttrain-auc:0.870711\ttest-auc:0.795666\n",
      "[424]\ttrain-auc:0.870892\ttest-auc:0.795578\n",
      "[425]\ttrain-auc:0.870977\ttest-auc:0.795707\n",
      "[426]\ttrain-auc:0.871088\ttest-auc:0.795619\n",
      "[427]\ttrain-auc:0.871153\ttest-auc:0.79568\n",
      "[428]\ttrain-auc:0.871282\ttest-auc:0.79551\n",
      "[429]\ttrain-auc:0.871372\ttest-auc:0.795653\n",
      "[430]\ttrain-auc:0.87154\ttest-auc:0.795578\n",
      "[431]\ttrain-auc:0.871623\ttest-auc:0.795741\n",
      "[432]\ttrain-auc:0.871718\ttest-auc:0.795803\n",
      "[433]\ttrain-auc:0.871888\ttest-auc:0.795878\n",
      "[434]\ttrain-auc:0.871998\ttest-auc:0.79581\n",
      "[435]\ttrain-auc:0.872133\ttest-auc:0.795946\n",
      "[436]\ttrain-auc:0.872236\ttest-auc:0.795885\n",
      "[437]\ttrain-auc:0.872348\ttest-auc:0.795701\n",
      "[438]\ttrain-auc:0.872454\ttest-auc:0.795673\n",
      "[439]\ttrain-auc:0.872544\ttest-auc:0.795823\n",
      "[440]\ttrain-auc:0.872639\ttest-auc:0.795932\n",
      "[441]\ttrain-auc:0.872734\ttest-auc:0.795926\n",
      "[442]\ttrain-auc:0.872811\ttest-auc:0.795939\n",
      "[443]\ttrain-auc:0.872894\ttest-auc:0.796144\n",
      "[444]\ttrain-auc:0.873003\ttest-auc:0.796219\n",
      "[445]\ttrain-auc:0.873112\ttest-auc:0.796239\n",
      "[446]\ttrain-auc:0.873177\ttest-auc:0.796437\n",
      "[447]\ttrain-auc:0.873227\ttest-auc:0.796403\n",
      "[448]\ttrain-auc:0.873347\ttest-auc:0.796424\n",
      "[449]\ttrain-auc:0.873408\ttest-auc:0.796321\n",
      "[450]\ttrain-auc:0.873484\ttest-auc:0.796274\n",
      "[451]\ttrain-auc:0.873578\ttest-auc:0.796294\n",
      "[452]\ttrain-auc:0.873661\ttest-auc:0.796342\n",
      "[453]\ttrain-auc:0.873819\ttest-auc:0.796471\n",
      "[454]\ttrain-auc:0.873972\ttest-auc:0.796499\n",
      "[455]\ttrain-auc:0.874034\ttest-auc:0.79643\n",
      "[456]\ttrain-auc:0.87415\ttest-auc:0.796376\n",
      "[457]\ttrain-auc:0.874225\ttest-auc:0.796396\n",
      "[458]\ttrain-auc:0.874288\ttest-auc:0.79639\n",
      "[459]\ttrain-auc:0.874421\ttest-auc:0.796574\n",
      "[460]\ttrain-auc:0.874492\ttest-auc:0.796615\n",
      "[461]\ttrain-auc:0.874563\ttest-auc:0.796601\n",
      "[462]\ttrain-auc:0.874661\ttest-auc:0.796737\n",
      "[463]\ttrain-auc:0.874736\ttest-auc:0.79671\n",
      "[464]\ttrain-auc:0.874819\ttest-auc:0.796737\n",
      "[465]\ttrain-auc:0.87491\ttest-auc:0.796853\n",
      "[466]\ttrain-auc:0.87504\ttest-auc:0.797092\n",
      "[467]\ttrain-auc:0.875108\ttest-auc:0.797256\n",
      "[468]\ttrain-auc:0.875217\ttest-auc:0.797454\n",
      "[469]\ttrain-auc:0.875336\ttest-auc:0.797495\n",
      "[470]\ttrain-auc:0.875513\ttest-auc:0.797563\n",
      "[471]\ttrain-auc:0.875633\ttest-auc:0.797535\n",
      "[472]\ttrain-auc:0.875722\ttest-auc:0.797495\n",
      "[473]\ttrain-auc:0.875851\ttest-auc:0.797576\n",
      "[474]\ttrain-auc:0.875972\ttest-auc:0.797535\n",
      "[475]\ttrain-auc:0.876059\ttest-auc:0.797563\n",
      "[476]\ttrain-auc:0.876163\ttest-auc:0.79759\n",
      "[477]\ttrain-auc:0.87624\ttest-auc:0.797631\n",
      "[478]\ttrain-auc:0.876354\ttest-auc:0.797672\n",
      "[479]\ttrain-auc:0.876474\ttest-auc:0.79759\n",
      "[480]\ttrain-auc:0.87657\ttest-auc:0.797617\n",
      "[481]\ttrain-auc:0.876643\ttest-auc:0.797651\n",
      "[482]\ttrain-auc:0.876735\ttest-auc:0.797658\n",
      "[483]\ttrain-auc:0.876845\ttest-auc:0.797726\n",
      "[484]\ttrain-auc:0.876946\ttest-auc:0.797651\n",
      "[485]\ttrain-auc:0.877046\ttest-auc:0.797645\n",
      "[486]\ttrain-auc:0.877148\ttest-auc:0.797699\n",
      "[487]\ttrain-auc:0.877222\ttest-auc:0.797604\n",
      "[488]\ttrain-auc:0.877314\ttest-auc:0.797563\n",
      "[489]\ttrain-auc:0.877393\ttest-auc:0.797515\n",
      "[490]\ttrain-auc:0.877493\ttest-auc:0.797692\n",
      "[491]\ttrain-auc:0.87763\ttest-auc:0.797658\n"
     ]
    }
   ],
   "source": [
    "bst=xgb.train(params,dtrain,num_boost_round=500,evals=watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Curve_for_hat(data, cutoff):\n",
    "    res = []\n",
    "    for items in data:\n",
    "        if items >= cutoff:\n",
    "            temp = 1\n",
    "        else:\n",
    "            temp = 0\n",
    "        res.append(temp)\n",
    "    res = np.array(res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat=bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = Curve_for_hat(Y_hat,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scores of XGB:\\n')\n",
    "print('F1 score:', f1_score(Y_test, Y_hat, average='binary', pos_label=1))\n",
    "print('Precision:', precision_score(Y_test, Y_hat, average='binary', pos_label=1))\n",
    "print('Recall:', recall_score(Y_test, Y_hat, average='binary', pos_label=1))\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
