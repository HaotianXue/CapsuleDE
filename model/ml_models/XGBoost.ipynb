{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HzT_WBWv3WR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import xgboost as xgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cLV-NJCwD06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "b5d6a954-f59d-49df-f3a0-f37e46095d0d"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hansWvPCwFQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = []  # 16659\n",
        "test_data = []  # 810"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGjkM6C_wGwO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "66945dcd-ae71-465d-c952-3e17ba9f33dc"
      },
      "source": [
        "'''读取文件'''\n",
        "print('Reading files...')\n",
        "print('\\n')\n",
        "train_f = open(\"train.txt\", encoding='utf-8')\n",
        "for line in train_f:\n",
        "    train_data.append(line)\n",
        "train_f.close()\n",
        "\n",
        "test_f = open(\"test.txt\", encoding='utf-8')\n",
        "for line in test_f:\n",
        "    test_data.append(line)\n",
        "test_f.close()\n",
        "print(train_data[0])\n",
        "print(test_data[0])\n",
        "print('\\n')\n",
        "print('Files get!...')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading files...\n",
            "\n",
            "\n",
            "\" 5 . Science includes such diverse fields as astronomy , biology , computer sciences , geology , logic , physics , chemistry , and mathematics ( [ link ] ) .\"\t\"0\"\n",
            "\n",
            "\" 2 . It becomes clear from this definition that the application of the scientific method plays a major role in science .\"\t\"0\"\n",
            "\n",
            "\n",
            "\n",
            "Files get!...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv_yr5B7wGty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "ddebb0de-28f8-4d58-e72a-0e7528a9eaa5"
      },
      "source": [
        "'''去掉开头序号-> [[句子(单词间以,为分割)], 0/1]'''\n",
        "print('Formatting...')\n",
        "print('\\n')\n",
        "train_set = []\n",
        "for unit in train_data:\n",
        "    temp = unit.split(' ')\n",
        "    if temp[1].isdigit():\n",
        "        # 判断第一个字符是否为数字，如果是则去掉，如果不是则取句子\n",
        "        temp = temp[3:-1]\n",
        "        # 当前temp中的最后一部分为\"\\t.\\n\",\"最后一个引号\" 为了保证格式规范，先去掉，最后在取corpus的时候加上句号即可\n",
        "        # training_set.append(([temp, unit[-3:-2]]))\n",
        "        train_set.append([' '.join(temp), unit[-3:-2]])\n",
        "        # unit[-3:-2]为当前句子的label\n",
        "    else:\n",
        "        # temp[1]为引号，应去掉\n",
        "        temp = temp[1:-1]\n",
        "        # training_set.append(([temp, unit[-3:-2]]))\n",
        "        train_set.append([' '.join(temp), unit[-3:-2]])\n",
        "\n",
        "test_set = []\n",
        "for unit in test_data:\n",
        "    temp = unit.split(' ')\n",
        "    if temp[1].isdigit():\n",
        "        temp = temp[3:-1]\n",
        "        # training_set.append(([temp, unit[-3:-2]]))\n",
        "        test_set.append([' '.join(temp), unit[-3:-2]])\n",
        "    else:\n",
        "        temp = temp[1:-1]\n",
        "        # training_set.append(([temp, unit[-3:-2]]))\n",
        "        test_set.append([' '.join(temp), unit[-3:-2]])\n",
        "\n",
        "print(train_set[0])\n",
        "print(test_set[0])\n",
        "print('\\n')\n",
        "print('All data sets are formatted!')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Formatting...\n",
            "\n",
            "\n",
            "['Science includes such diverse fields as astronomy , biology , computer sciences , geology , logic , physics , chemistry , and mathematics ( [ link ] )', '0']\n",
            "['It becomes clear from this definition that the application of the scientific method plays a major role in science', '0']\n",
            "\n",
            "\n",
            "All data sets are formatted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEB_sdwFwGr2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "bb513628-a202-424f-ff90-38455e7c6ecc"
      },
      "source": [
        "print('Tokenizeing...')\n",
        "print('\\n')\n",
        "\n",
        "def tokenize(data):\n",
        "    res = []\n",
        "    for samples in data:\n",
        "        # nltk.word_tokenize用于取tokens\n",
        "        temp_t = nltk.word_tokenize(samples[0])\n",
        "        res.append([temp_t, samples[1]])\n",
        "    return res\n",
        "\n",
        "\n",
        "train_set = tokenize(train_set)\n",
        "test_set = tokenize(test_set)\n",
        "print(train_set[0])\n",
        "print(test_set[0])\n",
        "print('\\n')\n",
        "print('Tokenization completed!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizeing...\n",
            "\n",
            "\n",
            "[['Science', 'includes', 'such', 'diverse', 'fields', 'as', 'astronomy', ',', 'biology', ',', 'computer', 'sciences', ',', 'geology', ',', 'logic', ',', 'physics', ',', 'chemistry', ',', 'and', 'mathematics', '(', '[', 'link', ']', ')'], '0']\n",
            "[['It', 'becomes', 'clear', 'from', 'this', 'definition', 'that', 'the', 'application', 'of', 'the', 'scientific', 'method', 'plays', 'a', 'major', 'role', 'in', 'science'], '0']\n",
            "\n",
            "\n",
            "Tokenization completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fydAYuMwGot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "41f49ccb-c447-40cc-bcdc-d6f7a3428ed9"
      },
      "source": [
        "print('Removing stopwords...')\n",
        "print('\\n')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "# stop_words为英文所有stop words的集合\n",
        "\n",
        "\n",
        "def Remove_stopwords(data):\n",
        "    res = []\n",
        "    temp = []\n",
        "    for sets in data:\n",
        "        for w in sets[0]:\n",
        "            # 如果对于句子中任意一个单词不属于stop_words则将其加入新的dataset\n",
        "            if w not in stop_words:\n",
        "                temp.append(w)\n",
        "        res.append([temp, sets[1]])\n",
        "        temp = []\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "train_set = Remove_stopwords(train_set)\n",
        "test_set = Remove_stopwords(test_set)\n",
        "print(train_set[0])\n",
        "print(test_set[0])\n",
        "print('\\n')\n",
        "print('Stopwords removed!')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Removing stopwords...\n",
            "\n",
            "\n",
            "[['Science', 'includes', 'diverse', 'fields', 'astronomy', ',', 'biology', ',', 'computer', 'sciences', ',', 'geology', ',', 'logic', ',', 'physics', ',', 'chemistry', ',', 'mathematics', '(', '[', 'link', ']', ')'], '0']\n",
            "[['It', 'becomes', 'clear', 'definition', 'application', 'scientific', 'method', 'plays', 'major', 'role', 'science'], '0']\n",
            "\n",
            "\n",
            "Stopwords removed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN-7gy2lwGNS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "ea33234d-0f08-4c83-f80f-bfc5e2002939"
      },
      "source": [
        "print('Stemming...')\n",
        "print('\\n')\n",
        "ps = PorterStemmer()\n",
        "\n",
        "\n",
        "def Stemming(data):\n",
        "    res = []\n",
        "    stemmed_words_temp = []\n",
        "    for units in data:\n",
        "        for w in units[0]:\n",
        "            #ps.stem(w):对当前单词w取stem word\n",
        "            stemmed_words_temp.append(ps.stem(w))\n",
        "\n",
        "        res.append([stemmed_words_temp, units[1]])\n",
        "        stemmed_words_temp = []\n",
        "    return res\n",
        "\n",
        "\n",
        "train_set = Stemming(train_set)\n",
        "test_set = Stemming(test_set)\n",
        "print(train_set[0])\n",
        "print(test_set[0])\n",
        "print('\\n')\n",
        "print('Stemming completed!')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemming...\n",
            "\n",
            "\n",
            "[['scienc', 'includ', 'divers', 'field', 'astronomi', ',', 'biolog', ',', 'comput', 'scienc', ',', 'geolog', ',', 'logic', ',', 'physic', ',', 'chemistri', ',', 'mathemat', '(', '[', 'link', ']', ')'], '0']\n",
            "[['It', 'becom', 'clear', 'definit', 'applic', 'scientif', 'method', 'play', 'major', 'role', 'scienc'], '0']\n",
            "\n",
            "\n",
            "Stemming completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDRGMuTSwGHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "ff320c08-200a-422c-9db8-ecb1cb03e775"
      },
      "source": [
        "print('Lemmatization...')\n",
        "print('\\n')\n",
        "lem = WordNetLemmatizer()\n",
        "stem = PorterStemmer()\n",
        "\n",
        "\n",
        "def Lemmatization(data):\n",
        "    lem_words_temp = []\n",
        "    res = []\n",
        "    for atoms in data:\n",
        "        for w in atoms[0]:\n",
        "            #lem.lemmatize(w, \"v\"): 对当前单词w取Lemmatization\n",
        "            lem_words_temp.append(lem.lemmatize(w, \"v\"))\n",
        "        res.append([lem_words_temp, atoms[1]])\n",
        "        lem_words_temp = []\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "train_set = Lemmatization(train_set)\n",
        "test_set = Lemmatization(test_set)\n",
        "print(train_set[0])\n",
        "print(test_set[0])\n",
        "print('\\n')\n",
        "print('Lemmatization completed!')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemmatization...\n",
            "\n",
            "\n",
            "[['scienc', 'includ', 'divers', 'field', 'astronomi', ',', 'biolog', ',', 'comput', 'scienc', ',', 'geolog', ',', 'logic', ',', 'physic', ',', 'chemistri', ',', 'mathemat', '(', '[', 'link', ']', ')'], '0']\n",
            "[['It', 'becom', 'clear', 'definit', 'applic', 'scientif', 'method', 'play', 'major', 'role', 'scienc'], '0']\n",
            "\n",
            "\n",
            "Lemmatization completed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2sH1RvywSkU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "e7b03714-f16e-43c8-b338-3168aedecc23"
      },
      "source": [
        "print('Corpus and labels gathering...')\n",
        "print('\\n')\n",
        "corpus_test = []\n",
        "corpus_train = []\n",
        "\n",
        "\n",
        "def Gathering_corpus(data):\n",
        "    res = []\n",
        "    temp_res = []\n",
        "    for aas in data:\n",
        "        #corpus中仅仅需要第一个unit，即句子\n",
        "        temp_res.append(aas[0])\n",
        "\n",
        "    for aaas in temp_res:\n",
        "        # 对于scikit-learn中的vectorizer，corpus必须为一句一句话的集合，而并非tokens。所以这里必须join然后加上句号。\n",
        "        temp_ff = ' '.join(aaas)\n",
        "        temp_ff = temp_ff + '.'\n",
        "        res.append(temp_ff)\n",
        "    return res\n",
        "\n",
        "\n",
        "corpus_train = Gathering_corpus(train_set)\n",
        "corpus_test = Gathering_corpus(test_set)\n",
        "# train和test的corpus之和，成为corpus_sum\n",
        "corpus_sum = []\n",
        "corpus_sum = corpus_train\n",
        "for things in corpus_test:\n",
        "    corpus_sum.append(things)\n",
        "print('len of corpus_sum:', len(corpus_sum))\n",
        "print(corpus_sum[:5])\n",
        "#取出label: Y_train and Y_test\n",
        "Y_train = []\n",
        "for thing in train_set:\n",
        "    Y_train.append(thing[1])\n",
        "Y_train = np.array(Y_train)\n",
        "Y_test = []\n",
        "for that in test_set:\n",
        "    Y_test.append(that[1])\n",
        "Y_test = np.array(Y_test)\n",
        "print(Y_train[:5])\n",
        "print(Y_test[:5])\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)\n",
        "print('\\n')\n",
        "print('Corpus and labels get!')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus and labels gathering...\n",
            "\n",
            "\n",
            "len of corpus_sum: 17469\n",
            "['scienc includ divers field astronomi , biolog , comput scienc , geolog , logic , physic , chemistri , mathemat ( [ link ] ).', 'howev , field scienc relat physic world phenomena process consid natur scienc.', 'thu , museum natur scienc might contain item list.', 'In deduct reason , pattern think move opposit direct compar induct reason.', 'deduct reason form logic think use gener principl law forecast specif result.']\n",
            "['0' '1' '0' '0' '1']\n",
            "['0' '1' '0' '1' '1']\n",
            "(16659,)\n",
            "(810,)\n",
            "\n",
            "\n",
            "Corpus and labels get!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh9jVzZxwU_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "ba8b6268-a115-4e74-ca7b-0f74684f298b"
      },
      "source": [
        "print('tfidf processing...')\n",
        "print('\\n')\n",
        "vectorizer_tfidf = TfidfVectorizer()\n",
        "X_tfidf = vectorizer_tfidf.fit_transform(corpus_sum)\n",
        "X_train_tfidf = X_tfidf[:16659]\n",
        "X_test_tfidf = X_tfidf[16659:17469]\n",
        "X_train_tfidf = X_train_tfidf.toarray()\n",
        "X_test_tfidf = X_test_tfidf.toarray()\n",
        "X_tfidf_arr = X_tfidf.toarray()\n",
        "print(X_train_tfidf.shape)\n",
        "print(X_test_tfidf.shape)\n",
        "print(X_tfidf_arr.shape)\n",
        "print('\\n')\n",
        "print('tfidf get!')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfidf processing...\n",
            "\n",
            "\n",
            "(16659, 14675)\n",
            "(810, 14675)\n",
            "(17469, 14675)\n",
            "\n",
            "\n",
            "tfidf get!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9d3TEA6wXNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Format_into_array(data):\n",
        "    res = []\n",
        "    for items in data:\n",
        "        temp = int(items)\n",
        "        res.append(temp)\n",
        "    res = np.array(res)\n",
        "    \n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8yKaYkBwYTE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8bf14be0-e81d-4a81-bd1b-7268b296a8d7"
      },
      "source": [
        "Y_test = Format_into_array(Y_test)\n",
        "Y_train = Format_into_array(Y_train)\n",
        "print(Y_test[:10])\n",
        "print(Y_train[:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 0 1 1 1 0 0 1 0]\n",
            "[0 1 0 0 1 0 0 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd3r7ooQwZJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtrain=xgb.DMatrix(X_train_tfidf,label=Y_train)\n",
        "dtest=xgb.DMatrix(X_test_tfidf, label=Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZldlCcNwbt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params={'booster':'gbtree',\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'auc',\n",
        "        'max_depth':35,\n",
        "        'lambda':15,\n",
        "        'subsample':0.75,\n",
        "        'colsample_bytree':0.75,\n",
        "        'min_child_weight':1.75,\n",
        "        'eta': 0.025,\n",
        "        'seed':0,\n",
        "        'silent':1,\n",
        "        'gamma':0.15,\n",
        "        'learning_rate' : 0.015}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cw4mZEzwbo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "watchlist = [(dtrain,'train'), (dtest,'test')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae43Nt_Bwe3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0484f90d-8459-4b5a-d3b1-909a962af315"
      },
      "source": [
        "bst=xgb.train(params,dtrain,num_boost_round=350,evals=watchlist)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-auc:0.659876\ttest-auc:0.635422\n",
            "[1]\ttrain-auc:0.709437\ttest-auc:0.663788\n",
            "[2]\ttrain-auc:0.732669\ttest-auc:0.703501\n",
            "[3]\ttrain-auc:0.738845\ttest-auc:0.709872\n",
            "[4]\ttrain-auc:0.744975\ttest-auc:0.72287\n",
            "[5]\ttrain-auc:0.748897\ttest-auc:0.723754\n",
            "[6]\ttrain-auc:0.751152\ttest-auc:0.731294\n",
            "[7]\ttrain-auc:0.752637\ttest-auc:0.729439\n",
            "[8]\ttrain-auc:0.753851\ttest-auc:0.731663\n",
            "[9]\ttrain-auc:0.756842\ttest-auc:0.734108\n",
            "[10]\ttrain-auc:0.757999\ttest-auc:0.734118\n",
            "[11]\ttrain-auc:0.760306\ttest-auc:0.734292\n",
            "[12]\ttrain-auc:0.760681\ttest-auc:0.733474\n",
            "[13]\ttrain-auc:0.761489\ttest-auc:0.734944\n",
            "[14]\ttrain-auc:0.766177\ttest-auc:0.739279\n",
            "[15]\ttrain-auc:0.767752\ttest-auc:0.740984\n",
            "[16]\ttrain-auc:0.767748\ttest-auc:0.740629\n",
            "[17]\ttrain-auc:0.768281\ttest-auc:0.744207\n",
            "[18]\ttrain-auc:0.769746\ttest-auc:0.743238\n",
            "[19]\ttrain-auc:0.770322\ttest-auc:0.743389\n",
            "[20]\ttrain-auc:0.770372\ttest-auc:0.745029\n",
            "[21]\ttrain-auc:0.773578\ttest-auc:0.740848\n",
            "[22]\ttrain-auc:0.773734\ttest-auc:0.740281\n",
            "[23]\ttrain-auc:0.775342\ttest-auc:0.739719\n",
            "[24]\ttrain-auc:0.77588\ttest-auc:0.740691\n",
            "[25]\ttrain-auc:0.776388\ttest-auc:0.743146\n",
            "[26]\ttrain-auc:0.777871\ttest-auc:0.743341\n",
            "[27]\ttrain-auc:0.778106\ttest-auc:0.743931\n",
            "[28]\ttrain-auc:0.778082\ttest-auc:0.743133\n",
            "[29]\ttrain-auc:0.779223\ttest-auc:0.74388\n",
            "[30]\ttrain-auc:0.779279\ttest-auc:0.7439\n",
            "[31]\ttrain-auc:0.780282\ttest-auc:0.74773\n",
            "[32]\ttrain-auc:0.780193\ttest-auc:0.747676\n",
            "[33]\ttrain-auc:0.780062\ttest-auc:0.747468\n",
            "[34]\ttrain-auc:0.780052\ttest-auc:0.747815\n",
            "[35]\ttrain-auc:0.780981\ttest-auc:0.747004\n",
            "[36]\ttrain-auc:0.78105\ttest-auc:0.748484\n",
            "[37]\ttrain-auc:0.781183\ttest-auc:0.749985\n",
            "[38]\ttrain-auc:0.781391\ttest-auc:0.75066\n",
            "[39]\ttrain-auc:0.781949\ttest-auc:0.752273\n",
            "[40]\ttrain-auc:0.782005\ttest-auc:0.752792\n",
            "[41]\ttrain-auc:0.782658\ttest-auc:0.753225\n",
            "[42]\ttrain-auc:0.783593\ttest-auc:0.753863\n",
            "[43]\ttrain-auc:0.784559\ttest-auc:0.755124\n",
            "[44]\ttrain-auc:0.784727\ttest-auc:0.754674\n",
            "[45]\ttrain-auc:0.786091\ttest-auc:0.755435\n",
            "[46]\ttrain-auc:0.786788\ttest-auc:0.756277\n",
            "[47]\ttrain-auc:0.78711\ttest-auc:0.756762\n",
            "[48]\ttrain-auc:0.787413\ttest-auc:0.759217\n",
            "[49]\ttrain-auc:0.788081\ttest-auc:0.758467\n",
            "[50]\ttrain-auc:0.788476\ttest-auc:0.758747\n",
            "[51]\ttrain-auc:0.788415\ttest-auc:0.758822\n",
            "[52]\ttrain-auc:0.789039\ttest-auc:0.759023\n",
            "[53]\ttrain-auc:0.789966\ttest-auc:0.759013\n",
            "[54]\ttrain-auc:0.790188\ttest-auc:0.761291\n",
            "[55]\ttrain-auc:0.791015\ttest-auc:0.761912\n",
            "[56]\ttrain-auc:0.791522\ttest-auc:0.762225\n",
            "[57]\ttrain-auc:0.792406\ttest-auc:0.763412\n",
            "[58]\ttrain-auc:0.792854\ttest-auc:0.763965\n",
            "[59]\ttrain-auc:0.793034\ttest-auc:0.763781\n",
            "[60]\ttrain-auc:0.793338\ttest-auc:0.764347\n",
            "[61]\ttrain-auc:0.793652\ttest-auc:0.764538\n",
            "[62]\ttrain-auc:0.794398\ttest-auc:0.765118\n",
            "[63]\ttrain-auc:0.794606\ttest-auc:0.764852\n",
            "[64]\ttrain-auc:0.794667\ttest-auc:0.764565\n",
            "[65]\ttrain-auc:0.795036\ttest-auc:0.764705\n",
            "[66]\ttrain-auc:0.795164\ttest-auc:0.765141\n",
            "[67]\ttrain-auc:0.795445\ttest-auc:0.765046\n",
            "[68]\ttrain-auc:0.795959\ttest-auc:0.76491\n",
            "[69]\ttrain-auc:0.796137\ttest-auc:0.76478\n",
            "[70]\ttrain-auc:0.796655\ttest-auc:0.765128\n",
            "[71]\ttrain-auc:0.797099\ttest-auc:0.765476\n",
            "[72]\ttrain-auc:0.797832\ttest-auc:0.765162\n",
            "[73]\ttrain-auc:0.798135\ttest-auc:0.764794\n",
            "[74]\ttrain-auc:0.798306\ttest-auc:0.764821\n",
            "[75]\ttrain-auc:0.798801\ttest-auc:0.766008\n",
            "[76]\ttrain-auc:0.799359\ttest-auc:0.766628\n",
            "[77]\ttrain-auc:0.799614\ttest-auc:0.766342\n",
            "[78]\ttrain-auc:0.80006\ttest-auc:0.767242\n",
            "[79]\ttrain-auc:0.800313\ttest-auc:0.767007\n",
            "[80]\ttrain-auc:0.800514\ttest-auc:0.767249\n",
            "[81]\ttrain-auc:0.801063\ttest-auc:0.767781\n",
            "[82]\ttrain-auc:0.801229\ttest-auc:0.768102\n",
            "[83]\ttrain-auc:0.801768\ttest-auc:0.768641\n",
            "[84]\ttrain-auc:0.802402\ttest-auc:0.769118\n",
            "[85]\ttrain-auc:0.802702\ttest-auc:0.769296\n",
            "[86]\ttrain-auc:0.803389\ttest-auc:0.768607\n",
            "[87]\ttrain-auc:0.803712\ttest-auc:0.769074\n",
            "[88]\ttrain-auc:0.803749\ttest-auc:0.769231\n",
            "[89]\ttrain-auc:0.804234\ttest-auc:0.769596\n",
            "[90]\ttrain-auc:0.804561\ttest-auc:0.770053\n",
            "[91]\ttrain-auc:0.805114\ttest-auc:0.770257\n",
            "[92]\ttrain-auc:0.805383\ttest-auc:0.770462\n",
            "[93]\ttrain-auc:0.805819\ttest-auc:0.770421\n",
            "[94]\ttrain-auc:0.806075\ttest-auc:0.771021\n",
            "[95]\ttrain-auc:0.806242\ttest-auc:0.771519\n",
            "[96]\ttrain-auc:0.806999\ttest-auc:0.772178\n",
            "[97]\ttrain-auc:0.807352\ttest-auc:0.772628\n",
            "[98]\ttrain-auc:0.807613\ttest-auc:0.77303\n",
            "[99]\ttrain-auc:0.807829\ttest-auc:0.772508\n",
            "[100]\ttrain-auc:0.808172\ttest-auc:0.77274\n",
            "[101]\ttrain-auc:0.808586\ttest-auc:0.773508\n",
            "[102]\ttrain-auc:0.808885\ttest-auc:0.774405\n",
            "[103]\ttrain-auc:0.809535\ttest-auc:0.77478\n",
            "[104]\ttrain-auc:0.80955\ttest-auc:0.774336\n",
            "[105]\ttrain-auc:0.809803\ttest-auc:0.774302\n",
            "[106]\ttrain-auc:0.810357\ttest-auc:0.77463\n",
            "[107]\ttrain-auc:0.81049\ttest-auc:0.774882\n",
            "[108]\ttrain-auc:0.810658\ttest-auc:0.774828\n",
            "[109]\ttrain-auc:0.810884\ttest-auc:0.774998\n",
            "[110]\ttrain-auc:0.811027\ttest-auc:0.775169\n",
            "[111]\ttrain-auc:0.811225\ttest-auc:0.775387\n",
            "[112]\ttrain-auc:0.811712\ttest-auc:0.775673\n",
            "[113]\ttrain-auc:0.812474\ttest-auc:0.775864\n",
            "[114]\ttrain-auc:0.812739\ttest-auc:0.776267\n",
            "[115]\ttrain-auc:0.812974\ttest-auc:0.776369\n",
            "[116]\ttrain-auc:0.813357\ttest-auc:0.776772\n",
            "[117]\ttrain-auc:0.813857\ttest-auc:0.77671\n",
            "[118]\ttrain-auc:0.814229\ttest-auc:0.777004\n",
            "[119]\ttrain-auc:0.814523\ttest-auc:0.777426\n",
            "[120]\ttrain-auc:0.815054\ttest-auc:0.77787\n",
            "[121]\ttrain-auc:0.815439\ttest-auc:0.778218\n",
            "[122]\ttrain-auc:0.816067\ttest-auc:0.778511\n",
            "[123]\ttrain-auc:0.816249\ttest-auc:0.778525\n",
            "[124]\ttrain-auc:0.816584\ttest-auc:0.778265\n",
            "[125]\ttrain-auc:0.816953\ttest-auc:0.778532\n",
            "[126]\ttrain-auc:0.817274\ttest-auc:0.778866\n",
            "[127]\ttrain-auc:0.817735\ttest-auc:0.779289\n",
            "[128]\ttrain-auc:0.818005\ttest-auc:0.77905\n",
            "[129]\ttrain-auc:0.818365\ttest-auc:0.779159\n",
            "[130]\ttrain-auc:0.818657\ttest-auc:0.779268\n",
            "[131]\ttrain-auc:0.818927\ttest-auc:0.779384\n",
            "[132]\ttrain-auc:0.819228\ttest-auc:0.779452\n",
            "[133]\ttrain-auc:0.819536\ttest-auc:0.779855\n",
            "[134]\ttrain-auc:0.820048\ttest-auc:0.780496\n",
            "[135]\ttrain-auc:0.82012\ttest-auc:0.780428\n",
            "[136]\ttrain-auc:0.820496\ttest-auc:0.780551\n",
            "[137]\ttrain-auc:0.820955\ttest-auc:0.781192\n",
            "[138]\ttrain-auc:0.821282\ttest-auc:0.780939\n",
            "[139]\ttrain-auc:0.821553\ttest-auc:0.780796\n",
            "[140]\ttrain-auc:0.82195\ttest-auc:0.781049\n",
            "[141]\ttrain-auc:0.822389\ttest-auc:0.781437\n",
            "[142]\ttrain-auc:0.8228\ttest-auc:0.781072\n",
            "[143]\ttrain-auc:0.822994\ttest-auc:0.781257\n",
            "[144]\ttrain-auc:0.823251\ttest-auc:0.781652\n",
            "[145]\ttrain-auc:0.823683\ttest-auc:0.781468\n",
            "[146]\ttrain-auc:0.824175\ttest-auc:0.781707\n",
            "[147]\ttrain-auc:0.824529\ttest-auc:0.781666\n",
            "[148]\ttrain-auc:0.824683\ttest-auc:0.782\n",
            "[149]\ttrain-auc:0.824963\ttest-auc:0.78245\n",
            "[150]\ttrain-auc:0.825226\ttest-auc:0.782484\n",
            "[151]\ttrain-auc:0.82552\ttest-auc:0.782512\n",
            "[152]\ttrain-auc:0.82556\ttest-auc:0.782334\n",
            "[153]\ttrain-auc:0.825751\ttest-auc:0.782573\n",
            "[154]\ttrain-auc:0.826035\ttest-auc:0.782505\n",
            "[155]\ttrain-auc:0.826225\ttest-auc:0.782539\n",
            "[156]\ttrain-auc:0.826678\ttest-auc:0.782283\n",
            "[157]\ttrain-auc:0.826828\ttest-auc:0.782529\n",
            "[158]\ttrain-auc:0.827126\ttest-auc:0.782542\n",
            "[159]\ttrain-auc:0.827381\ttest-auc:0.782481\n",
            "[160]\ttrain-auc:0.827472\ttest-auc:0.782631\n",
            "[161]\ttrain-auc:0.827613\ttest-auc:0.782959\n",
            "[162]\ttrain-auc:0.827956\ttest-auc:0.783245\n",
            "[163]\ttrain-auc:0.828209\ttest-auc:0.783327\n",
            "[164]\ttrain-auc:0.828481\ttest-auc:0.782863\n",
            "[165]\ttrain-auc:0.828788\ttest-auc:0.783129\n",
            "[166]\ttrain-auc:0.828948\ttest-auc:0.783102\n",
            "[167]\ttrain-auc:0.8292\ttest-auc:0.782945\n",
            "[168]\ttrain-auc:0.829417\ttest-auc:0.783231\n",
            "[169]\ttrain-auc:0.829555\ttest-auc:0.783238\n",
            "[170]\ttrain-auc:0.82987\ttest-auc:0.78345\n",
            "[171]\ttrain-auc:0.829991\ttest-auc:0.783259\n",
            "[172]\ttrain-auc:0.830323\ttest-auc:0.783293\n",
            "[173]\ttrain-auc:0.830549\ttest-auc:0.783634\n",
            "[174]\ttrain-auc:0.830817\ttest-auc:0.783811\n",
            "[175]\ttrain-auc:0.831153\ttest-auc:0.784139\n",
            "[176]\ttrain-auc:0.831297\ttest-auc:0.783961\n",
            "[177]\ttrain-auc:0.831528\ttest-auc:0.784036\n",
            "[178]\ttrain-auc:0.831785\ttest-auc:0.78407\n",
            "[179]\ttrain-auc:0.831985\ttest-auc:0.784077\n",
            "[180]\ttrain-auc:0.832216\ttest-auc:0.783757\n",
            "[181]\ttrain-auc:0.832367\ttest-auc:0.783927\n",
            "[182]\ttrain-auc:0.832667\ttest-auc:0.78418\n",
            "[183]\ttrain-auc:0.832989\ttest-auc:0.784118\n",
            "[184]\ttrain-auc:0.833258\ttest-auc:0.784159\n",
            "[185]\ttrain-auc:0.833418\ttest-auc:0.784238\n",
            "[186]\ttrain-auc:0.833647\ttest-auc:0.784197\n",
            "[187]\ttrain-auc:0.833909\ttest-auc:0.784128\n",
            "[188]\ttrain-auc:0.833994\ttest-auc:0.784313\n",
            "[189]\ttrain-auc:0.83418\ttest-auc:0.784579\n",
            "[190]\ttrain-auc:0.834429\ttest-auc:0.784633\n",
            "[191]\ttrain-auc:0.83467\ttest-auc:0.784838\n",
            "[192]\ttrain-auc:0.834881\ttest-auc:0.784831\n",
            "[193]\ttrain-auc:0.835026\ttest-auc:0.785063\n",
            "[194]\ttrain-auc:0.835196\ttest-auc:0.78507\n",
            "[195]\ttrain-auc:0.835394\ttest-auc:0.785097\n",
            "[196]\ttrain-auc:0.835626\ttest-auc:0.785383\n",
            "[197]\ttrain-auc:0.835703\ttest-auc:0.785206\n",
            "[198]\ttrain-auc:0.835867\ttest-auc:0.78522\n",
            "[199]\ttrain-auc:0.836068\ttest-auc:0.785233\n",
            "[200]\ttrain-auc:0.836287\ttest-auc:0.785199\n",
            "[201]\ttrain-auc:0.836544\ttest-auc:0.785346\n",
            "[202]\ttrain-auc:0.836811\ttest-auc:0.78523\n",
            "[203]\ttrain-auc:0.836905\ttest-auc:0.785196\n",
            "[204]\ttrain-auc:0.837092\ttest-auc:0.785407\n",
            "[205]\ttrain-auc:0.837329\ttest-auc:0.785134\n",
            "[206]\ttrain-auc:0.837537\ttest-auc:0.785134\n",
            "[207]\ttrain-auc:0.83773\ttest-auc:0.78508\n",
            "[208]\ttrain-auc:0.837826\ttest-auc:0.784926\n",
            "[209]\ttrain-auc:0.838024\ttest-auc:0.784981\n",
            "[210]\ttrain-auc:0.838121\ttest-auc:0.785172\n",
            "[211]\ttrain-auc:0.83831\ttest-auc:0.785506\n",
            "[212]\ttrain-auc:0.838413\ttest-auc:0.785339\n",
            "[213]\ttrain-auc:0.838595\ttest-auc:0.785121\n",
            "[214]\ttrain-auc:0.838772\ttest-auc:0.78521\n",
            "[215]\ttrain-auc:0.838955\ttest-auc:0.785066\n",
            "[216]\ttrain-auc:0.839027\ttest-auc:0.785435\n",
            "[217]\ttrain-auc:0.839194\ttest-auc:0.785441\n",
            "[218]\ttrain-auc:0.839363\ttest-auc:0.785435\n",
            "[219]\ttrain-auc:0.839537\ttest-auc:0.785435\n",
            "[220]\ttrain-auc:0.83978\ttest-auc:0.785639\n",
            "[221]\ttrain-auc:0.839969\ttest-auc:0.785612\n",
            "[222]\ttrain-auc:0.840086\ttest-auc:0.785591\n",
            "[223]\ttrain-auc:0.840223\ttest-auc:0.78568\n",
            "[224]\ttrain-auc:0.840411\ttest-auc:0.785728\n",
            "[225]\ttrain-auc:0.840649\ttest-auc:0.785871\n",
            "[226]\ttrain-auc:0.840849\ttest-auc:0.786062\n",
            "[227]\ttrain-auc:0.841094\ttest-auc:0.786369\n",
            "[228]\ttrain-auc:0.841263\ttest-auc:0.786403\n",
            "[229]\ttrain-auc:0.841383\ttest-auc:0.786437\n",
            "[230]\ttrain-auc:0.841608\ttest-auc:0.786458\n",
            "[231]\ttrain-auc:0.841841\ttest-auc:0.786553\n",
            "[232]\ttrain-auc:0.842039\ttest-auc:0.786662\n",
            "[233]\ttrain-auc:0.842215\ttest-auc:0.786853\n",
            "[234]\ttrain-auc:0.842391\ttest-auc:0.787092\n",
            "[235]\ttrain-auc:0.842589\ttest-auc:0.787044\n",
            "[236]\ttrain-auc:0.842835\ttest-auc:0.787072\n",
            "[237]\ttrain-auc:0.843015\ttest-auc:0.787167\n",
            "[238]\ttrain-auc:0.843098\ttest-auc:0.787106\n",
            "[239]\ttrain-auc:0.843157\ttest-auc:0.787024\n",
            "[240]\ttrain-auc:0.843306\ttest-auc:0.787147\n",
            "[241]\ttrain-auc:0.843444\ttest-auc:0.787194\n",
            "[242]\ttrain-auc:0.84363\ttest-auc:0.787133\n",
            "[243]\ttrain-auc:0.843727\ttest-auc:0.787249\n",
            "[244]\ttrain-auc:0.843878\ttest-auc:0.787624\n",
            "[245]\ttrain-auc:0.84402\ttest-auc:0.78758\n",
            "[246]\ttrain-auc:0.844163\ttest-auc:0.787723\n",
            "[247]\ttrain-auc:0.844334\ttest-auc:0.787805\n",
            "[248]\ttrain-auc:0.844556\ttest-auc:0.787689\n",
            "[249]\ttrain-auc:0.844738\ttest-auc:0.78743\n",
            "[250]\ttrain-auc:0.844875\ttest-auc:0.787505\n",
            "[251]\ttrain-auc:0.844975\ttest-auc:0.787566\n",
            "[252]\ttrain-auc:0.845115\ttest-auc:0.787512\n",
            "[253]\ttrain-auc:0.845269\ttest-auc:0.787464\n",
            "[254]\ttrain-auc:0.845417\ttest-auc:0.7873\n",
            "[255]\ttrain-auc:0.845551\ttest-auc:0.78758\n",
            "[256]\ttrain-auc:0.845637\ttest-auc:0.787819\n",
            "[257]\ttrain-auc:0.845767\ttest-auc:0.787703\n",
            "[258]\ttrain-auc:0.845862\ttest-auc:0.787798\n",
            "[259]\ttrain-auc:0.845954\ttest-auc:0.788098\n",
            "[260]\ttrain-auc:0.846115\ttest-auc:0.787846\n",
            "[261]\ttrain-auc:0.846245\ttest-auc:0.788044\n",
            "[262]\ttrain-auc:0.846465\ttest-auc:0.787986\n",
            "[263]\ttrain-auc:0.846627\ttest-auc:0.787808\n",
            "[264]\ttrain-auc:0.846793\ttest-auc:0.787808\n",
            "[265]\ttrain-auc:0.846901\ttest-auc:0.788033\n",
            "[266]\ttrain-auc:0.847034\ttest-auc:0.788068\n",
            "[267]\ttrain-auc:0.847144\ttest-auc:0.788122\n",
            "[268]\ttrain-auc:0.847268\ttest-auc:0.787924\n",
            "[269]\ttrain-auc:0.847393\ttest-auc:0.78802\n",
            "[270]\ttrain-auc:0.847594\ttest-auc:0.78832\n",
            "[271]\ttrain-auc:0.847678\ttest-auc:0.78834\n",
            "[272]\ttrain-auc:0.847817\ttest-auc:0.788381\n",
            "[273]\ttrain-auc:0.847976\ttest-auc:0.788115\n",
            "[274]\ttrain-auc:0.84805\ttest-auc:0.788245\n",
            "[275]\ttrain-auc:0.848204\ttest-auc:0.788395\n",
            "[276]\ttrain-auc:0.848387\ttest-auc:0.788231\n",
            "[277]\ttrain-auc:0.848622\ttest-auc:0.788143\n",
            "[278]\ttrain-auc:0.84875\ttest-auc:0.788306\n",
            "[279]\ttrain-auc:0.848864\ttest-auc:0.7883\n",
            "[280]\ttrain-auc:0.848985\ttest-auc:0.788354\n",
            "[281]\ttrain-auc:0.849146\ttest-auc:0.788627\n",
            "[282]\ttrain-auc:0.849261\ttest-auc:0.788934\n",
            "[283]\ttrain-auc:0.849431\ttest-auc:0.789016\n",
            "[284]\ttrain-auc:0.849643\ttest-auc:0.788832\n",
            "[285]\ttrain-auc:0.849814\ttest-auc:0.789029\n",
            "[286]\ttrain-auc:0.84992\ttest-auc:0.789029\n",
            "[287]\ttrain-auc:0.850049\ttest-auc:0.788866\n",
            "[288]\ttrain-auc:0.850188\ttest-auc:0.789029\n",
            "[289]\ttrain-auc:0.85033\ttest-auc:0.789275\n",
            "[290]\ttrain-auc:0.850465\ttest-auc:0.789405\n",
            "[291]\ttrain-auc:0.850566\ttest-auc:0.789534\n",
            "[292]\ttrain-auc:0.850712\ttest-auc:0.789398\n",
            "[293]\ttrain-auc:0.850817\ttest-auc:0.78935\n",
            "[294]\ttrain-auc:0.85094\ttest-auc:0.789411\n",
            "[295]\ttrain-auc:0.85111\ttest-auc:0.789343\n",
            "[296]\ttrain-auc:0.851215\ttest-auc:0.789548\n",
            "[297]\ttrain-auc:0.85134\ttest-auc:0.789698\n",
            "[298]\ttrain-auc:0.851481\ttest-auc:0.790018\n",
            "[299]\ttrain-auc:0.851625\ttest-auc:0.789759\n",
            "[300]\ttrain-auc:0.851752\ttest-auc:0.789602\n",
            "[301]\ttrain-auc:0.851862\ttest-auc:0.789561\n",
            "[302]\ttrain-auc:0.852005\ttest-auc:0.789555\n",
            "[303]\ttrain-auc:0.852104\ttest-auc:0.789596\n",
            "[304]\ttrain-auc:0.852218\ttest-auc:0.789596\n",
            "[305]\ttrain-auc:0.85231\ttest-auc:0.789466\n",
            "[306]\ttrain-auc:0.852415\ttest-auc:0.789418\n",
            "[307]\ttrain-auc:0.852544\ttest-auc:0.789657\n",
            "[308]\ttrain-auc:0.852706\ttest-auc:0.789684\n",
            "[309]\ttrain-auc:0.852848\ttest-auc:0.789466\n",
            "[310]\ttrain-auc:0.852982\ttest-auc:0.789534\n",
            "[311]\ttrain-auc:0.853113\ttest-auc:0.789657\n",
            "[312]\ttrain-auc:0.853232\ttest-auc:0.789698\n",
            "[313]\ttrain-auc:0.853348\ttest-auc:0.789746\n",
            "[314]\ttrain-auc:0.853485\ttest-auc:0.789793\n",
            "[315]\ttrain-auc:0.853659\ttest-auc:0.789827\n",
            "[316]\ttrain-auc:0.853814\ttest-auc:0.78995\n",
            "[317]\ttrain-auc:0.853965\ttest-auc:0.790244\n",
            "[318]\ttrain-auc:0.854074\ttest-auc:0.790209\n",
            "[319]\ttrain-auc:0.854156\ttest-auc:0.790155\n",
            "[320]\ttrain-auc:0.85433\ttest-auc:0.790469\n",
            "[321]\ttrain-auc:0.854436\ttest-auc:0.790441\n",
            "[322]\ttrain-auc:0.854586\ttest-auc:0.790209\n",
            "[323]\ttrain-auc:0.854737\ttest-auc:0.790455\n",
            "[324]\ttrain-auc:0.854849\ttest-auc:0.790551\n",
            "[325]\ttrain-auc:0.855008\ttest-auc:0.790544\n",
            "[326]\ttrain-auc:0.855173\ttest-auc:0.790585\n",
            "[327]\ttrain-auc:0.855266\ttest-auc:0.790619\n",
            "[328]\ttrain-auc:0.855322\ttest-auc:0.790591\n",
            "[329]\ttrain-auc:0.855436\ttest-auc:0.790619\n",
            "[330]\ttrain-auc:0.855554\ttest-auc:0.790782\n",
            "[331]\ttrain-auc:0.855722\ttest-auc:0.790748\n",
            "[332]\ttrain-auc:0.855909\ttest-auc:0.790755\n",
            "[333]\ttrain-auc:0.856064\ttest-auc:0.79081\n",
            "[334]\ttrain-auc:0.856208\ttest-auc:0.791096\n",
            "[335]\ttrain-auc:0.856328\ttest-auc:0.791069\n",
            "[336]\ttrain-auc:0.856494\ttest-auc:0.791089\n",
            "[337]\ttrain-auc:0.856587\ttest-auc:0.791137\n",
            "[338]\ttrain-auc:0.856697\ttest-auc:0.791096\n",
            "[339]\ttrain-auc:0.856842\ttest-auc:0.790892\n",
            "[340]\ttrain-auc:0.857002\ttest-auc:0.790926\n",
            "[341]\ttrain-auc:0.85713\ttest-auc:0.790817\n",
            "[342]\ttrain-auc:0.85724\ttest-auc:0.790946\n",
            "[343]\ttrain-auc:0.857351\ttest-auc:0.790721\n",
            "[344]\ttrain-auc:0.857438\ttest-auc:0.790796\n",
            "[345]\ttrain-auc:0.857576\ttest-auc:0.790926\n",
            "[346]\ttrain-auc:0.857684\ttest-auc:0.791045\n",
            "[347]\ttrain-auc:0.857822\ttest-auc:0.791042\n",
            "[348]\ttrain-auc:0.857937\ttest-auc:0.790933\n",
            "[349]\ttrain-auc:0.85807\ttest-auc:0.791089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11aEhygbwhsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Curve_for_hat(data, cutoff):\n",
        "    res = []\n",
        "    for items in data:\n",
        "        if items >= cutoff:\n",
        "            temp = 1\n",
        "        else:\n",
        "            temp = 0\n",
        "        res.append(temp)\n",
        "    res = np.array(res)\n",
        "    \n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr67hYjwwiZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_hat=bst.predict(dtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUZzBWJIwkUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_hat = Curve_for_hat(Y_hat,0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcIL6P9XwlQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "43ecbb0e-5ca9-4ae7-8c17-5d5989e6af65"
      },
      "source": [
        "print('Scores of XGB:\\n')\n",
        "print('F1 score:', f1_score(Y_test, Y_hat, average='binary', pos_label=1))\n",
        "print('Precision:', precision_score(Y_test, Y_hat, average='binary', pos_label=1))\n",
        "print('Recall:', recall_score(Y_test, Y_hat, average='binary', pos_label=1))\n",
        "print('Accuracy:', accuracy_score(Y_test, Y_hat))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores of XGB:\n",
            "\n",
            "F1 score: 0.6226415094339622\n",
            "Precision: 0.5454545454545454\n",
            "Recall: 0.7252747252747253\n",
            "Accuracy: 0.7037037037037037\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}